# Code Challenge

Setup:
  ✔ Start a repository for this code challenge @started(21-01-28 18:44) @done(21-01-28 18:44) @lasted(0s)
  ✔ Read and understand the Challenge doc @started(21-01-28 18:44) @done(21-01-28 19:17) @lasted(33m4s)
  ✔ Converting document from PDF to Markdown for archive purpose @started(21-01-28 18:45) @done(21-01-28 18:52) @lasted(7m10s)

Basic Crash Processor:
  Setup:
    ✔ create Ruby on Rails API-only application @started(21-01-28 19:19) @done(21-01-28 19:33) @lasted(14m50s)
    ✔ Write meaningful Readme @started(21-01-28 19:35) @done(21-01-28 20:00) @lasted(25m22s)
    ✔ Setup CI/CD @started(21-01-28 20:04) @done(21-01-28 20:09) @lasted(5m11s)
    ✔ Add RSpec for convenient request testing @started(21-01-28 20:00) @done(21-01-28 20:03) @lasted(3m46s)
  Endpoint:
    POST /notify
    ✔ Redis dependency @done(21-01-28 20:09)
    ✔ Notifier endpont @started(21-01-28 20:09) @done(21-01-28 20:15) @lasted(6m15s)
    ✔ Queue a job to process the payload @started(21-01-28 20:34) @done(21-01-28 21:00) @lasted(26m5s)
    ✔ Respond with HTTP 202 @started(21-01-28 20:14) @done(21-01-28 20:14) @lasted(36s)
    ✘ Document with Apiaray @started(21-01-28 21:05) @cancelled(21-01-28 21:20) @wasted(15m32s)
    ☐ Secure the API
  ActionJob asynchronous processor:
    ✔ validate payload (using the API spec in CHALLENGE.md) @started(21-01-28 20:34) @done(21-01-28 22:27) @lasted(1h53m42s)
    ✔ count invalid notifications @started(21-01-28 21:20) @done(21-01-28 22:17) @lasted(57m36s)
    ✔ count valid notifications of kind @started(21-01-28 22:19) @done(21-01-28 22:26) @lasted(7m56s)
    ✘ random slowdown between 10ms - 1000ms @cancelled(21-01-28 22:27)
      is this really required in production?

Statistics endpoint:
  GET /projects/1/stats
  ✔ Show invalid counter @started(21-01-28 22:28) @done(21-01-28 23:31) @lasted(1h3m59s)
    initially wanted to use [ActiveModelSerializers](https://github.com/rails-api/active_model_serializers), but it is not maintained anymore, so quickly picked a alternative gem.
    I previously used RABL years ago, I had to dig deep in my knowlage to remember how this worked. 
    Over all, I would not have been happy with to_json for a long term solution.
  ✔ show `error` counter @done(21-01-28 23:32)
  ✔ show `warning` counter @done(21-01-28 23:32)
  ✔ show `info` counter @done(21-01-28 23:32)

Custom statistics:
  ☐ filter results by metadata
    - Count the instances of `metadata.subscription.level = "pro plan"` for projectId "100"
    - Count the instances of `metadata.query.stats.duration > 1000` for projectId "200"
  ☐ return results with the previous statistics endpoint

Concurrency:
  this might be already done with the ActionJob processor
  ☐ Check service can handle multiple notifications at the same time

Fair useage:
  avoid a single `projectId` from dominating the notify queue. 
  Early considerations would be to check the queue for the same `projectId` and schedule the events to happen at a later date. 
  Or
  Have a sweeping Job that would batch the events a single job if the given `projectId` throughput is becoming too high.
  Would likely need to have a quick redis check before scheduling the job for the throughput for a given `projectId`.